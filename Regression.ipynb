{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import neighbors\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import ExtraTreesRegressor, IsolationForest\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, ElasticNet, Lasso, LassoCV\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import xgboost as xgb\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "plt.style.use('fivethirtyeight') \n",
    "mpl.rcParams['lines.linewidth'] = 2\n",
    "# mpl.rcParams['axes.labelsize'] = 14\n",
    "# mpl.rcParams['xtick.labelsize'] = 12\n",
    "# mpl.rcParams['ytick.labelsize'] = 12\n",
    "mpl.rcParams['text.color'] = 'k'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "y = pd.read_csv('y_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X_test.keys():\n",
    "    X_train[i].fillna(X_train[i].median(), inplace = True)\n",
    "for i in X_test.keys():\n",
    "    X_test[i].fillna(X_test[i].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>% Outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>x629</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>x193</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>x339</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>x297</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>x85</td>\n",
       "      <td>13.366337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>x383</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>x382</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>x380</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>x379</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>x831</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>833 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Variable  % Outliers\n",
       "630     x629  100.000000\n",
       "194     x193  100.000000\n",
       "340     x339  100.000000\n",
       "298     x297  100.000000\n",
       "86       x85   13.366337\n",
       "..       ...         ...\n",
       "384     x383    0.000000\n",
       "383     x382    0.000000\n",
       "381     x380    0.000000\n",
       "380     x379    0.000000\n",
       "832     x831    0.000000\n",
       "\n",
       "[833 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outlier detection amonge features by interquartile range\n",
    "outliers_percentage = []\n",
    "variables = []\n",
    "for k, v in X_train.items():\n",
    "    Q1 = v.quantile(0.25)\n",
    "    Q3 = v.quantile(0.75)\n",
    "    IRQ = Q3 - Q1\n",
    "    v_col = v[(v <= Q1 - 1.5 * IRQ) | (v >= Q3 + 1.5 * IRQ)]\n",
    "    perc = np.shape(v_col)[0] * 100.0 / np.shape(X_train)[0]\n",
    "    outliers_percentage.append(perc)\n",
    "    variables.append(k)\n",
    "#     print(\"Column %s outliers = %.2f%%\" % (k, perc))\n",
    "\n",
    "outliers_inTrain = pd.DataFrame({'Variable':variables, '% Outliers':outliers_percentage })\n",
    "outliers_inTrain.sort_values(by=[\"% Outliers\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier elemination of features\n",
    "X_train = X_train.drop(['id', 'x629','x193','x339','x297'], axis=1)\n",
    "X_test = X_test.drop(['id', 'x629','x193','x339','x297'], axis=1)\n",
    "y = y.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier detection of data\n",
    "x = X_train.values\n",
    "clf = IsolationForest(random_state=0,contamination=.1).fit(x)\n",
    "prediction = clf.predict(x)\n",
    "idx = np.where(prediction<0)\n",
    "# eleminate outliers \n",
    "x[idx[0],:]=np.nan\n",
    "# knn imputation\n",
    "imp= KNNImputer(n_neighbors=2)\n",
    "x_clean = imp.fit_transform(x)\n",
    "X_train = pd.DataFrame(data = x_clean, columns=X_train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSE \n",
    "# a = sm.OLS(y, X_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2=0.063\n",
      "10-fold Crossvalidation: R2 Mean 0.041 StdDev 0.059\n"
     ]
    }
   ],
   "source": [
    "# Baseline performance with simple linear regression\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "seed = 1234\n",
    "kfolds = KFold(10,shuffle=True,random_state=seed)\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X_train , y)\n",
    "reg_scores = cross_val_score(model, X_train , y, cv=kfolds)\n",
    "yp = model.predict(X_train )\n",
    "\n",
    "print(\"R2=%.3f\"%(r2_score(y, yp)))\n",
    "print(\"10-fold Crossvalidation: R2 Mean %.3f StdDev %.3f\"%(reg_scores.mean(),reg_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced data set shape =  (1212, 100)\n",
      "     Selected features =  Index(['x7', 'x30', 'x41', 'x52', 'x68', 'x75', 'x76', 'x81', 'x85', 'x87',\n",
      "       'x101', 'x129', 'x134', 'x139', 'x140', 'x148', 'x170', 'x180', 'x183',\n",
      "       'x184', 'x192', 'x196', 'x204', 'x210', 'x214', 'x222', 'x223', 'x224',\n",
      "       'x227', 'x234', 'x239', 'x240', 'x247', 'x262', 'x282', 'x285', 'x289',\n",
      "       'x292', 'x300', 'x301', 'x302', 'x334', 'x352', 'x360', 'x375', 'x382',\n",
      "       'x384', 'x387', 'x390', 'x408', 'x417', 'x441', 'x442', 'x447', 'x448',\n",
      "       'x457', 'x464', 'x465', 'x466', 'x471', 'x473', 'x482', 'x494', 'x496',\n",
      "       'x498', 'x504', 'x508', 'x514', 'x523', 'x537', 'x559', 'x578', 'x579',\n",
      "       'x583', 'x590', 'x597', 'x599', 'x619', 'x648', 'x661', 'x662', 'x669',\n",
      "       'x672', 'x685', 'x686', 'x711', 'x717', 'x723', 'x726', 'x757', 'x759',\n",
      "       'x772', 'x776', 'x785', 'x789', 'x791', 'x792', 'x800', 'x819', 'x823'],\n",
      "      dtype='object')\n",
      "      Deleted Features =  Index(['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x8', 'x9', 'x10',\n",
      "       ...\n",
      "       'x821', 'x822', 'x824', 'x825', 'x826', 'x827', 'x828', 'x829', 'x830',\n",
      "       'x831'],\n",
      "      dtype='object', length=728)\n"
     ]
    }
   ],
   "source": [
    "# apply the procedure to take the best k variables based on mutual_info_regression\n",
    "feature_selection_univariate_model = SelectKBest(mutual_info_regression, k=100)\n",
    "\n",
    "# fit the feature selection model and select the four variables\n",
    "X_selected_features_univariate = feature_selection_univariate_model.fit_transform(X_train ,y['y'])\n",
    "\n",
    "mask = feature_selection_univariate_model.get_support() #list of booleans\n",
    "print(\"Reduced data set shape = \",X_selected_features_univariate.shape)\n",
    "print(\"     Selected features = \",X_train .keys()[mask])\n",
    "print(\"      Deleted Features = \", X_train .keys()[~mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2=0.851\n"
     ]
    }
   ],
   "source": [
    "# the best result(6387) piplien --> imputation by median, outlier detection of features,\n",
    "# eleminate outlier features, outlier detection on data by isolation forest, impute by knn, mutual info reg feature selection,\n",
    "# extra trees regressor\n",
    "etr = ExtraTreesRegressor(n_estimators=100, random_state=0).fit(X_train.values[: ,mask], y['y'].values)\n",
    "yp = etr.predict(X_train.values[: ,mask])\n",
    "print(\"R2=%.3f\"%(r2_score(y['y'], yp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Crossvalidation R2: Mean 0.417 StdDev 0.048\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(etr, X_train, y['y'],cv=10)\n",
    "print(\"10-fold Crossvalidation R2: Mean %.3f StdDev %.3f\"%(scores.mean(),scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([70.51, 70.93, 71.61, 68.05, 71.06, 73.38, 71.57, 71.48, 80.06,\n",
       "       78.7 , 65.37, 78.9 , 71.08, 74.67, 61.56, 83.41, 69.58, 75.1 ,\n",
       "       68.24, 71.58, 69.79, 68.57, 75.12, 76.57, 62.59, 66.41, 58.43,\n",
       "       72.41, 64.32, 64.77, 58.6 , 69.72, 62.76, 66.93, 75.36, 64.71,\n",
       "       72.45, 58.61, 59.46, 67.41, 73.36, 77.61, 73.77, 78.64, 77.56,\n",
       "       70.02, 66.76, 72.72, 76.09, 63.95, 73.84, 69.28, 66.2 , 79.55,\n",
       "       75.57, 74.54, 72.81, 75.46, 66.4 , 62.65, 60.12, 68.98, 65.43,\n",
       "       62.96, 73.41, 59.99, 75.15, 78.23, 64.97, 74.18, 69.91, 76.92,\n",
       "       62.66, 59.44, 66.7 , 76.89, 72.32, 60.06, 83.77, 84.2 , 70.45,\n",
       "       75.09, 71.86, 73.59, 63.04, 67.67, 55.12, 71.32, 77.91, 79.88,\n",
       "       68.66, 65.33, 76.7 , 66.15, 67.61, 66.18, 67.81, 67.62, 68.64,\n",
       "       75.98, 76.5 , 62.44, 76.86, 79.48, 78.21, 66.11, 64.23, 64.55,\n",
       "       72.53, 61.93, 70.59, 66.19, 76.25, 65.46, 68.62, 74.14, 77.82,\n",
       "       75.52, 71.82, 69.07, 75.04, 79.33, 60.56, 59.11, 75.93, 66.87,\n",
       "       61.55, 74.98, 75.57, 65.72, 64.99, 76.8 , 64.96, 61.07, 77.61,\n",
       "       67.8 , 74.81, 75.97, 79.52, 66.8 , 69.68, 57.73, 76.97, 74.58,\n",
       "       75.78, 66.14, 65.45, 57.61, 73.6 , 73.43, 74.91, 75.99, 78.95,\n",
       "       65.86, 79.24, 64.57, 63.48, 70.22, 76.18, 78.29, 75.18, 62.91,\n",
       "       76.81, 59.13, 68.66, 69.36, 72.79, 81.23, 70.6 , 78.17, 66.31,\n",
       "       66.6 , 63.07, 66.76, 78.39, 64.77, 76.56, 76.08, 62.19, 62.82,\n",
       "       58.87, 62.33, 73.96, 58.24, 63.95, 61.41, 58.82, 69.23, 58.31,\n",
       "       64.37, 71.9 , 63.06, 79.4 , 66.11, 63.69, 77.44, 72.99, 74.58,\n",
       "       57.7 , 65.43, 63.11, 67.24, 71.25, 76.57, 72.08, 69.45, 63.57,\n",
       "       74.85, 57.34, 66.07, 78.53, 67.04, 72.17, 76.18, 58.07, 72.36,\n",
       "       72.66, 72.64, 67.88, 81.72, 55.09, 72.25, 61.91, 73.84, 62.28,\n",
       "       64.89, 77.46, 71.42, 67.45, 64.1 , 63.37, 57.25, 67.22, 71.33,\n",
       "       74.01, 75.37, 68.05, 70.  , 74.78, 59.93, 62.57, 48.81, 67.38,\n",
       "       64.88, 71.59, 66.15, 61.26, 62.58, 84.7 , 62.03, 61.65, 69.17,\n",
       "       74.85, 67.43, 64.  , 80.5 , 74.99, 76.48, 57.58, 64.16, 70.7 ,\n",
       "       71.84, 59.26, 76.11, 74.37, 65.79, 65.29, 77.63, 71.93, 75.02,\n",
       "       67.59, 65.3 , 74.6 , 59.2 , 63.23, 77.08, 76.77, 52.56, 76.31,\n",
       "       70.97, 62.99, 64.85, 78.48, 60.37, 67.55, 83.08, 65.13, 63.3 ,\n",
       "       66.5 , 71.16, 70.77, 65.29, 74.17, 64.36, 78.02, 61.82, 75.17,\n",
       "       64.94, 65.46, 64.19, 72.42, 75.51, 74.82, 79.04, 65.16, 67.14,\n",
       "       69.41, 68.49, 79.34, 65.39, 77.47, 74.34, 68.65, 60.65, 69.69,\n",
       "       68.31, 68.93, 80.75, 64.54, 65.32, 72.59, 64.99, 64.45, 78.43,\n",
       "       70.32, 78.94, 57.24, 60.6 , 64.2 , 63.97, 74.81, 56.53, 71.17,\n",
       "       71.75, 68.81, 64.06, 62.32, 78.67, 79.13, 78.58, 66.94, 74.59,\n",
       "       63.37, 68.3 , 70.23, 68.55, 76.43, 73.73, 72.36, 69.99, 69.7 ,\n",
       "       77.08, 70.37, 77.47, 63.59, 64.85, 65.28, 69.8 , 61.98, 77.34,\n",
       "       67.8 , 60.36, 77.62, 75.77, 65.89, 67.27, 78.5 , 78.37, 84.88,\n",
       "       68.03, 60.84, 71.33, 65.98, 58.61, 66.93, 75.19, 67.41, 66.8 ,\n",
       "       80.87, 74.33, 76.89, 77.6 , 69.12, 64.84, 69.74, 73.11, 73.53,\n",
       "       78.35, 60.64, 64.63, 68.67, 68.5 , 58.07, 77.29, 75.06, 62.76,\n",
       "       67.64, 64.09, 59.82, 61.31, 79.22, 67.97, 77.94, 75.82, 72.82,\n",
       "       68.17, 61.99, 62.21, 66.73, 70.87, 66.95, 63.8 , 71.2 , 78.67,\n",
       "       61.09, 70.93, 65.65, 70.74, 71.87, 62.67, 64.46, 75.24, 70.39,\n",
       "       71.04, 72.61, 67.78, 71.  , 62.55, 63.32, 66.98, 75.31, 59.74,\n",
       "       63.05, 71.88, 63.4 , 62.6 , 74.18, 66.86, 70.74, 77.9 , 65.05,\n",
       "       73.55, 76.51, 71.48, 69.52, 77.18, 73.23, 56.93, 63.37, 69.1 ,\n",
       "       65.74, 76.09, 68.28, 68.32, 65.31, 71.05, 71.69, 76.81, 67.99,\n",
       "       70.16, 67.02, 67.23, 66.57, 71.04, 73.38, 75.68, 74.21, 65.81,\n",
       "       68.69, 69.37, 67.17, 62.94, 73.71, 76.4 , 61.17, 63.75, 60.55,\n",
       "       75.17, 72.69, 74.67, 62.48, 68.45, 56.09, 75.15, 77.83, 66.6 ,\n",
       "       77.34, 65.31, 63.22, 65.59, 72.39, 61.56, 69.13, 79.25, 72.99,\n",
       "       76.7 , 70.02, 83.52, 72.55, 62.06, 73.4 , 66.41, 66.79, 65.49,\n",
       "       76.2 , 62.13, 65.88, 78.88, 71.2 , 69.5 , 74.83, 68.89, 76.19,\n",
       "       81.49, 61.1 , 78.96, 69.79, 65.07, 68.85, 74.02, 66.93, 72.11,\n",
       "       68.26, 63.78, 79.24, 78.79, 72.56, 63.42, 77.41, 63.9 , 77.98,\n",
       "       65.8 , 67.74, 75.03, 64.84, 71.1 , 82.38, 64.59, 74.42, 73.41,\n",
       "       67.66, 57.3 , 65.16, 63.49, 70.51, 72.48, 59.28, 64.04, 69.04,\n",
       "       67.11, 62.12, 76.07, 61.32, 79.15, 77.62, 72.25, 66.56, 75.21,\n",
       "       71.59, 70.78, 62.94, 67.62, 68.18, 64.11, 78.3 , 69.91, 77.43,\n",
       "       64.33, 71.33, 76.52, 75.35, 73.81, 75.97, 59.1 , 74.3 , 76.08,\n",
       "       65.17, 58.35, 60.3 , 71.18, 66.09, 76.84, 69.  , 66.98, 70.29,\n",
       "       72.49, 75.74, 70.71, 63.5 , 73.05, 85.28, 73.79, 67.32, 77.28,\n",
       "       75.29, 69.3 , 71.53, 77.27, 70.82, 67.25, 63.9 , 66.09, 80.24,\n",
       "       67.2 , 69.39, 66.95, 62.42, 75.49, 60.94, 68.42, 69.15, 72.78,\n",
       "       67.77, 66.29, 68.33, 69.34, 66.05, 76.31, 66.79, 66.99, 67.  ,\n",
       "       84.77, 61.17, 73.51, 83.3 , 76.55, 76.18, 66.64, 65.84, 79.07,\n",
       "       71.46, 74.59, 69.04, 68.59, 63.44, 71.09, 73.63, 68.63, 66.35,\n",
       "       66.87, 69.06, 62.4 , 75.64, 77.62, 66.64, 67.41, 52.9 , 62.14,\n",
       "       77.89, 64.9 , 73.82, 74.  , 68.28, 69.01, 64.12, 66.8 , 77.61,\n",
       "       72.78, 63.17, 61.91, 76.19, 67.75, 70.14, 69.68, 73.72, 77.03,\n",
       "       64.75, 74.97, 72.17, 75.3 , 64.44, 63.49, 76.13, 62.42, 71.96,\n",
       "       76.89, 72.32, 77.18, 65.63, 77.31, 59.99, 68.74, 54.41, 72.72,\n",
       "       60.68, 62.9 , 66.33, 76.52, 70.65, 62.05, 65.07, 71.21, 71.7 ,\n",
       "       71.6 , 73.69, 58.29, 76.34, 76.01, 66.45, 79.52, 63.94, 72.81,\n",
       "       60.38, 64.85, 58.99, 78.94, 63.37, 77.37, 68.3 , 62.74, 59.39,\n",
       "       72.81, 66.37, 63.99, 60.78, 53.42, 71.41, 66.7 , 71.99, 78.56,\n",
       "       64.37, 83.03, 76.84, 74.33, 81.65, 80.35, 59.39, 68.32, 66.77,\n",
       "       76.13, 71.54, 73.01, 74.72, 71.51, 77.  , 69.14, 73.46, 81.  ,\n",
       "       70.85, 75.76, 63.54, 65.65, 83.28, 76.55, 70.07, 79.56, 74.21,\n",
       "       62.8 , 62.54, 75.09, 62.92, 60.66, 62.25, 68.68, 63.04, 71.18,\n",
       "       63.37, 69.68, 72.25, 65.98, 57.88, 77.26, 73.47, 56.73, 67.79,\n",
       "       75.79, 70.74, 78.18, 75.46, 61.85, 65.65, 62.79, 76.83, 77.41,\n",
       "       76.23, 72.88])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp = etr.predict(X_test.values[: ,mask])\n",
    "idx = [float(i) for i in range(len(yp))]\n",
    "result = pd.DataFrame({'id':idx, 'y':yp})\n",
    "result.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2=0.356\n",
      "10-fold Crossvalidation R2: Mean 0.205 StdDev 0.114\n"
     ]
    }
   ],
   "source": [
    "# best result(6374) pipline: same as extra trees regressor\n",
    "model_ridge = RidgeCV(alphas = [.1, .9, 10, 50, 100], cv=KFold(10, shuffle=True, random_state=12345678)).fit(X_train.values[:,mask], y['y'])\n",
    "ridge_scores = cross_val_score(model_ridge, X_train.values[:,mask], y['y'], cv=kfolds)\n",
    "yp = model_ridge.predict(X_train.values[:,mask])\n",
    "print(\"R2=%.3f\"%(r2_score(y['y'], yp)))\n",
    "print(\"10-fold Crossvalidation R2: Mean %.3f StdDev %.3f\"%(ridge_scores.mean(),ridge_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = model_ridge.predict(X_test.values[: ,mask])\n",
    "idx = [float(i) for i in range(len(yp))]\n",
    "result = pd.DataFrame({'id':idx, 'y':yp})\n",
    "result.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2=0.311\n",
      "10-fold Crossvalidation R2: Mean 0.256 StdDev 0.114\n"
     ]
    }
   ],
   "source": [
    "# poor result (.0269)!\n",
    "model_lasso = LassoCV(alphas = [.1, .9, 10, 50, 100],cv=KFold(10, shuffle=True, random_state=12345678), max_iter=10000, tol=0.001).fit(X_train.values[:,mask], y['y'].values)\n",
    "model_lasso.fit(X_train.values[:,mask], y['y'].values)\n",
    "yp = model_lasso.predict(X_train.values[:,mask])\n",
    "lasso_scores = cross_val_score(model_lasso, X_train.values[:,mask], y['y'].values, cv=kfolds)\n",
    "print(\"R2=%.3f\"%(r2_score(y['y'], yp)))\n",
    "print(\"10-fold Crossvalidation R2: Mean %.3f StdDev %.3f\"%(lasso_scores.mean(),lasso_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = reg.predict(X_test.values[: ,mask])\n",
    "idx = [float(i) for i in range(len(yp))]\n",
    "result = pd.DataFrame({'id':idx, 'y':yp})\n",
    "result.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr = xgb.XGBRegressor(verbosity=0)\n",
    "xgbr.fit(X_train, y['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.8505395143252663\n"
     ]
    }
   ],
   "source": [
    "# The best result(.5857) pipline: imputation by median, outlier detection of features, eleminate outlier features,\n",
    "score = xgbr.score(X_train, y['y'])  \n",
    "print(\"Training score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Crossvalidation R2: Mean 0.356 StdDev 0.049\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(xgbr, X_train, y['y'],cv=10)\n",
    "print(\"10-fold Crossvalidation R2: Mean %.3f StdDev %.3f\"%(scores.mean(),scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = xgbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [float(i) for i in range(len(yp))]\n",
    "result = pd.DataFrame({'id':idx, 'y':yp})\n",
    "result.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.3436620650077785\n"
     ]
    }
   ],
   "source": [
    "# best result (.5296) pipline: same as extra trees regressor\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "regr.fit(X_train.values[:,mask], y['y'])\n",
    "score = regr.score(X_train.values[:,mask], y['y']) \n",
    "print(\"Training score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Crossvalidation R2: Mean 0.298 StdDev 0.062\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(regr, X_train.values[:,mask], y['y'],cv=10)\n",
    "print(\"10-fold Crossvalidation R2: Mean %.3f StdDev %.3f\"%(scores.mean(),scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.8318315207295708\n"
     ]
    }
   ],
   "source": [
    "# with estimator [ridge, randomfores] and final extratreesregressor --> .48\n",
    "# with estimator [ridge, extratreesregressor] and final xgbr --> .5\n",
    "estimators = [\n",
    "     ('lr', ExtraTreesRegressor(n_estimators=100, random_state=0)),\n",
    "     ('svr', xgbr),\n",
    "     ('rd', model_ridge)]\n",
    "stack_reg = StackingRegressor(\n",
    "      estimators=estimators,\n",
    "      final_estimator= model)\n",
    "stack_reg.fit(X_train.values[:,mask], y['y'])\n",
    "score = stack_reg.score(X_train.values[:,mask], y['y'])\n",
    "print(\"Training score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Crossvalidation R2: Mean 0.458 StdDev 0.057\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(stack_reg, X_train.values[:,mask], y['y'],cv=10)\n",
    "print(\"10-fold Crossvalidation R2: Mean %.3f StdDev %.3f\"%(scores.mean(),scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = stack_reg.predict(X_test.values[: ,mask])\n",
    "idx = [float(i) for i in range(len(yp))]\n",
    "result = pd.DataFrame({'id':idx, 'y':yp})\n",
    "result.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  -8.642678081760631e+31\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp = MLPRegressor(random_state=1, max_iter=500).fit(X_train.values[:,mask], y['y'])\n",
    "yp = mlp.predict(X_train.values[:,mask])\n",
    "score = mlp.score(X_train.values[:,mask], y['y'])\n",
    "print(\"Training score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:55:07] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:55:07] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:55:07] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:55:07] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:55:07] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:55:07] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:55:07] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:55:07] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:55:08] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:55:08] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:55:11] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:55:11] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:55:11] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:55:11] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:55:12] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:55:12] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:55:12] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:55:12] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:55:12] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:55:12] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best rmse as a function of l1:\n",
      "     l1      rmse\n",
      "0  0.01  7.916308\n",
      "1  0.10  8.001649\n"
     ]
    }
   ],
   "source": [
    "# xgboost with l1 regularization\n",
    "dm = xgb.DMatrix(data = X_train, label = y)\n",
    "params = {'objective':'reg:linear', 'max_depth':'4'}\n",
    "l1_params = [.01, .1]\n",
    "rmse_l1 = []\n",
    "for reg in l1_params:\n",
    "    params['alpha'] = reg\n",
    "    cv_results = xgb.cv(dtrain = dm, params=params, nfold = 10, num_boost_round = 10,\n",
    "                        metrics = 'rmse', as_pandas = True, seed = 123)\n",
    "    rmse_l1.append(cv_results['test-rmse-mean'].tail(1).values[0])\n",
    "print('best rmse as a function of l1:')\n",
    "print(pd.DataFrame(list(zip(l1_params, rmse_l1)), columns = ['l1','rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import (RationalQuadratic, Exponentiation)\n",
    "kernel = CompoundKernel([WhiteKernel(noise_level=3.0), RBF(length_scale=2.0)])\n",
    "gpr = GaussianProcessRegressor(kernel=kernel,\n",
    "         random_state=0).fit(X_train.values[:,mask], y['y'])\n",
    "score =  gpr.score(X_train.values[:,mask], y['y'])\n",
    "print(\"Training score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abe/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter gamma is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning,\n",
      "/home/abe/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter gamma is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning,\n",
      "/home/abe/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter gamma is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning,\n",
      "/home/abe/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter gamma is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning,\n",
      "/home/abe/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter gamma is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning,\n",
      "/home/abe/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter gamma is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning,\n",
      "/home/abe/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter gamma is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning,\n",
      "/home/abe/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter gamma is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning,\n",
      "/home/abe/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter gamma is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Crossvalidation R2: Mean -68217245571488464.000 StdDev 137323722037408768.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abe/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter gamma is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(gpr, X_train.values[:,mask], y['y'],cv=10)\n",
    "print(\"10-fold Crossvalidation R2: Mean %.3f StdDev %.3f\"%(scores.mean(),scores.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
